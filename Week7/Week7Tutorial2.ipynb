{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Week7Tutorial2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOcuAW87/DhReWAGpWf2MqO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ebatty/MathToolsforNeuroscience/blob/stats_section/Week7/Week7Tutorial2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9l0lyqLvkW7"
      },
      "source": [
        "# Week 7: Probability & Statistics II\n",
        "\n",
        "# Tutorial 2\n",
        "\n",
        "# [insert your name]\n",
        "\n",
        "**Important reminders**: Before starting, click \"File -> Save a copy in Drive\". Produce a pdf for submission by \"File -> Print\" and then choose \"Save to PDF\".\n",
        "\n",
        "To complete this tutorial, you should have watched Videos 7.1 - 7.4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "cv9HSBNPyLV9"
      },
      "source": [
        "# @markdown Imports\n",
        "\n",
        "# Imports\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets  # interactive display\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIdPVYl9TzmK",
        "cellView": "form"
      },
      "source": [
        "# @markdown Plotting functions\n",
        "import numpy\n",
        "from numpy.linalg import inv, eig\n",
        "from math import ceil\n",
        "from matplotlib import pyplot, ticker, get_backend, rc\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from itertools import cycle\n",
        "\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "plt.style.use(\"https://raw.githubusercontent.com/NeuromatchAcademy/course-content/master/nma.mplstyle\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wYVn_J5Vhsc"
      },
      "source": [
        "# Exercise 1: Estimators for mean and variance of a normal distribution\n",
        "(Inspired in part by a question on HW5 from Eero Simoncelli/Mike Landys Math Tools 2019 course)\n",
        "\n",
        "Note that below we will look at the mean and variance of an estimator for the mean and the mean and variance for an estimator for the variance. This can get a bit confusing so try to keep straight what's happening! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyqQRQgjYART"
      },
      "source": [
        "## A) Mean estimation\n",
        "Let's examine two possible estimators for the mean of a normal distribution based on a sample.\n",
        "\n",
        "The first is estimating the mean of the population using the mean of the sample. The second is estimating the mean of the population using the median of the sample.  We looked at the first estimator in Video 7.3 and showed it was unbiased.\n",
        "\n",
        "Execute the next cell to draw 10000 samples each of size 10 from $N(0|1)$, compute these two estimators, and plot the histograms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdmyjR8iVrfp"
      },
      "source": [
        "n_samples = 100000\n",
        "sample_size = 10\n",
        "\n",
        "mean_estimators = np.zeros(n_samples,)\n",
        "median_estimators = np.zeros(n_samples,)\n",
        "for i_sample in range(n_samples):\n",
        "    sample = np.random.normal(size=(sample_size,))\n",
        "    mean_estimators[i_sample] = np.mean(sample)\n",
        "    median_estimators[i_sample] = np.median(sample)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5), sharey=True, sharex=True)\n",
        "axes[0].hist(mean_estimators, 100);\n",
        "axes[1].hist(median_estimators, 100);\n",
        "axes[0].set(title='Mean of Sample Estimator', xlabel='Estimator value');\n",
        "axes[1].set(title='Median of Sample Estimator', xlabel='Estimator value');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHwT-jakYDYG"
      },
      "source": [
        "Is the median estimator biased or unbiased? Which estimator would you pick to use and why? Note that if things aren't clear from the histogram, you are encouraged to compute the mean and variance of the two estimators (from the simulated values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttsTdnemYQx4"
      },
      "source": [
        "### **Answer**\n",
        "<font color='green'><span style=\"font-size:larger;\">\n",
        "Text answer here\n",
        "</font> </span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7CshZhMktn1"
      },
      "source": [
        "We can show that the variance of the sample mean estimator is $Var(\\hat{\\mu}) = \\frac{\\sigma^2}{N}$ where N is the size of the sample. Thus, the variance decreasing with increasing sample size - this makes sense!\n",
        "\n",
        "See here for a proof/explanation: https://online.stat.psu.edu/stat414/lesson/24/24.4.\n",
        "\n",
        "Does the variance of the mean estimators from the simulations match this? Show it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftvxiYoRky_C"
      },
      "source": [
        "### **Answer**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OI66eB09k0xw"
      },
      "source": [
        "# your code answer here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU1V5YTflLrm"
      },
      "source": [
        "<font color='green'><span style=\"font-size:larger;\">\n",
        "Text explanation here\n",
        "</font> </span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybJiAiR3YzC0"
      },
      "source": [
        "## B) Variance estimation\n",
        "\n",
        "Remember that using the sample variance to estimate the population variance is biased? Let's prove this to ourselves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sbwOPoaWcbS"
      },
      "source": [
        "n_samples = 100000\n",
        "sample_size = 10\n",
        "\n",
        "variance_estimators = np.zeros(n_samples,)\n",
        "for i_sample in range(n_samples):\n",
        "    sample = np.random.normal(size=(sample_size,))\n",
        "    variance_estimators[i_sample] = np.var(sample)\n",
        "fig, axes = plt.subplots(1, 1, figsize=(5, 5), sharey=True, sharex=True)\n",
        "axes.hist(variance_estimators, 100);\n",
        "axes.set(title='Variance of Sample Estimator', xlabel='Estimator value');\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "st33ZO5BZoHr"
      },
      "source": [
        "i) Prove to me that the variance of the sample is a biased estimator for the variance of the population. Note I'm not asking you the analytical proof (this is a bit long) but a simple proof based on the above simulation. \n",
        "\n",
        "ii) Show that adjusting the estimator as described in the video (so the estimator is $\\hat{\\sigma^2} = \\frac{1}{N-1} \\sum (X_i - \\bar{X})^2)$ results in an unbiased estimator. (Do this by creating this new estimator)\n",
        "\n",
        "iii) Based on the simulations, is the variance of the original estimator (the variance of the sample, $\\hat{\\sigma^2} = \\frac{1}{N} \\sum (X_i - \\bar{X})^2)$) or the adjusted estimator ($\\hat{\\sigma^2} = \\frac{1}{N-1} \\sum (X_i - \\bar{X})^2)$ higher? Which one has a higher mean squared error? Why do the answers to these two questions make sense together?\n",
        "\n",
        "You will need to use code for all of these questions but also explain in text!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uKh_z48Z0s2"
      },
      "source": [
        "### **Answer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUiB1JO3Z1qG"
      },
      "source": [
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGlLVe9dZWF-"
      },
      "source": [
        "<font color='green'><span style=\"font-size:larger;\">\n",
        "Text explanation\n",
        "</font> </span>"
      ]
    }
  ]
}